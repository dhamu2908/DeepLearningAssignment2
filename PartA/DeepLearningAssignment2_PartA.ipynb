{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWuPrsYvi03VF7ts3NTVnk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhamu2908/DeepLearningAssignment2/blob/main/DeepLearningAssignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15hMWUxxbIfJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "387e4f10-e7e7-4892-bba8-e4f67ade5a40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nDeep Learning Assignment 2\\nCS24M027 Dhamodharan Muthu Muniyandi\\nIIT MADRAS\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "\"\"\"\n",
        "Deep Learning Assignment 2\n",
        "CS24M027 Dhamodharan Muthu Muniyandi\n",
        "IIT MADRAS\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "#Data Accessing check\n",
        "\n",
        "print(\"Exploring contents of /kaggle/input/dldata:\")\n",
        "dataset_path = \"/kaggle/input/dldata/inaturalist_12K\"\n",
        "train_path = os.path.join(dataset_path, \"train\")\n",
        "val_path = os.path.join(dataset_path, \"val\")\n",
        "\n",
        "# Verifying the existence of directories\n",
        "is_train_available = os.path.isdir(train_path)\n",
        "is_val_available = os.path.isdir(val_path)\n",
        "\n",
        "\n",
        "print(f\"Train directory found: {is_train_available}\")\n",
        "print(f\"Validation directory found: {is_val_available}\")\n",
        "\n",
        "if is_train_available:\n",
        "    print(\"Sample items in training folder:\", os.listdir(train_path)[:5])\n",
        "\n",
        "if is_val_available:\n",
        "    print(\"Sample items in validation folder:\", os.listdir(val_path)[:5])"
      ],
      "metadata": {
        "id": "k2qREJMUkC-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import wandb"
      ],
      "metadata": {
        "id": "xs61B-TSkDAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize WandB\n",
        "wandb.login(key = \"\" )"
      ],
      "metadata": {
        "id": "VqpIvaD6kDC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training configuration parameters\n",
        "config = {\n",
        "    \"num_epochs\": 10,\n",
        "    \"lr\": 1e-4,\n",
        "    \"batch_sz\": 32,\n",
        "    \"backbone\": \"resnet50\",\n",
        "    \"unfreeze_layers\": 1\n",
        "}\n",
        "\n",
        "IMG_DIM = 224\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "# Function to divide dataset into training and validation sets while preserving class balance\n",
        "def stratified_split(dataset, train_frac):\n",
        "    train_ids = []\n",
        "    val_ids = []\n",
        "\n",
        "    # Index ranges for each class (based on specific dataset arrangement)\n",
        "    class_boundaries = [\n",
        "        (0, 999), (1000, 1999), (2000, 2999), (3000, 3999), (4000, 4998),\n",
        "        (4999, 5998), (5999, 6998), (6999, 7998), (7999, 8998), (8999, 9998)\n",
        "    ]\n",
        "\n",
        "    for lower, upper in class_boundaries:\n",
        "        indices = list(range(lower, upper + 1))\n",
        "        split_point = int(len(indices) * train_frac)\n",
        "        train_ids.extend(indices[:split_point])\n",
        "        val_ids.extend(indices[split_point:])\n",
        "\n",
        "    training_data = Subset(dataset, train_ids)\n",
        "    validation_data = Subset(dataset, val_ids)\n",
        "\n",
        "    return training_data, validation_data\n"
      ],
      "metadata": {
        "id": "sANVJlZ5kDFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Responsible for creating data loaders and returning dataset statistics\n",
        "def build_data_pipeline(config):\n",
        "    size = (IMAGE_DIMENSION, IMAGE_DIMENSION)\n",
        "\n",
        "    def get_transform():\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize(size),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "    # Define paths for training and testing datasets\n",
        "    path_train = \"/kaggle/input/nature1/inaturalist_12K/train\"\n",
        "    path_test = \"/kaggle/input/nature1/inaturalist_12K/val\"\n",
        "\n",
        "    # Load raw datasets\n",
        "    complete_train_dataset = ImageFolder(root=path_train, transform=get_transform())\n",
        "    test_dataset = ImageFolder(root=path_test, transform=get_transform())\n",
        "\n",
        "    # Split training set into train and validation sets\n",
        "    splitter = DatasetSplitter(complete_train_dataset, 0.8)\n",
        "    train_subset, val_subset = splitter.perform_split()\n",
        "\n",
        "    # Create data loaders\n",
        "    bs = config[\"batch_size\"]\n",
        "    loader_train = DataLoader(train_subset, batch_size=bs, shuffle=True)\n",
        "    loader_val = DataLoader(val_subset, batch_size=bs, shuffle=True)\n",
        "    loader_test = DataLoader(test_dataset, batch_size=bs, shuffle=True)\n",
        "\n",
        "    # Return everything in a structured dictionary\n",
        "    return {\n",
        "        \"train_size\": len(train_subset),\n",
        "        \"val_size\": len(val_subset),\n",
        "        \"test_size\": len(test_dataset),\n",
        "        \"train_loader\": loader_train,\n",
        "        \"val_loader\": loader_val,\n",
        "        \"test_loader\": loader_test\n",
        "    }\n"
      ],
      "metadata": {
        "id": "EGGwEEbJkDH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constructs and customizes a ResNet-50 model based on the provided configuration\n",
        "def build_resnet_model(config):\n",
        "    from torchvision.models import resnet50\n",
        "\n",
        "    # Load pretrained ResNet-50 architecture\n",
        "    resnet = resnet50(weights=\"IMAGENET1K_V1\")\n",
        "    input_features = resnet.fc.in_features\n",
        "\n",
        "    # Replace the final layer to match the number of output classes\n",
        "    resnet.fc = torch.nn.Linear(input_features, TOTAL_CLASSES)\n",
        "\n",
        "    # Initially freeze all layers\n",
        "    for param in resnet.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Selectively unfreeze last 'k' layers\n",
        "    unfreeze_count = config[\"unfreeze_layers\"]\n",
        "    if unfreeze_count > 0:\n",
        "        for param in list(resnet.parameters())[-unfreeze_count:]:\n",
        "            param.requires_grad = True\n",
        "\n",
        "    return resnet\n"
      ],
      "metadata": {
        "id": "AP9gXO2qkDKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trains a model using the provided configuration and dataset, logs metrics to Weights & Biases\n",
        "def run_training(config, dataset_bundle):\n",
        "    import wandb\n",
        "\n",
        "    # Set device context\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Model setup\n",
        "    model = build_resnet_model(config)\n",
        "    model = torch.nn.DataParallel(model, device_ids=[0]).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
        "\n",
        "    # Load training and validation data\n",
        "    train_loader = dataset_bundle[\"train_loader\"]\n",
        "    val_loader = dataset_bundle[\"val_loader\"]\n",
        "    n_train = dataset_bundle[\"train_size\"]\n",
        "    n_val = dataset_bundle[\"val_size\"]\n",
        "\n",
        "    for ep in range(config[\"num_epochs\"]):\n",
        "        model.train()\n",
        "        train_loss_accumulator = 0.0\n",
        "        correct_train_preds = 0\n",
        "\n",
        "        for step, (x_batch, y_batch) in enumerate(train_loader):\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x_batch)\n",
        "            loss = criterion(logits, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss_accumulator += loss.item()\n",
        "            correct_train_preds += (logits.argmax(dim=1) == y_batch).sum().item()\n",
        "\n",
        "            if step % 10 == 0:\n",
        "                batch_acc = (logits.argmax(1) == y_batch).float().mean().item()\n",
        "                print(f\"[Epoch {ep} | Batch {step}] Accuracy: {batch_acc:.4f}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        model.eval()\n",
        "        val_loss_accumulator = 0.0\n",
        "        correct_val_preds = 0\n",
        "        with torch.no_grad():\n",
        "            for x_val, y_val in val_loader:\n",
        "                x_val, y_val = x_val.to(device), y_val.to(device)\n",
        "                val_logits = model(x_val)\n",
        "                loss = criterion(val_logits, y_val)\n",
        "                val_loss_accumulator += loss.item()\n",
        "                correct_val_preds += (val_logits.argmax(1) == y_val).sum().item()\n",
        "\n",
        "        # Calculate and log metrics\n",
        "        train_accuracy = correct_train_preds / n_train\n",
        "        train_loss = train_loss_accumulator / len(train_loader)\n",
        "        val_accuracy = correct_val_preds / n_val\n",
        "        val_loss = val_loss_accumulator / len(val_loader)\n",
        "\n",
        "        print(f\"Epoch {ep} | Train Acc: {train_accuracy:.4f} | Train Loss: {train_loss:.4f} | Val Acc: {val_accuracy:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "        wandb.log({\n",
        "            \"epoch\": ep,\n",
        "            \"train_accuracy\": train_accuracy,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"val_accuracy\": val_accuracy,\n",
        "            \"val_loss\": val_loss\n",
        "        })\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "    torch.save(model.state_dict(), \"./model.pth\")\n"
      ],
      "metadata": {
        "id": "wfR1YU6okDLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign config object\n",
        "experiment_config = config  # renamed from h_params for consistency\n",
        "\n",
        "# Prepare the dataset\n",
        "data_bundle = build_data_pipeline(experiment_config)\n",
        "\n",
        "# Initialize Weights & Biases for logging\n",
        "run_name = f\"{experiment_config['backbone']}_epochs{experiment_config['num_epochs']}_bs{experiment_config['batch_sz']}_lr{experiment_config['lr']}_unfreeze{experiment_config['unfreeze_layers']}\"\n",
        "wandb_run = wandb.init(\n",
        "    project=\"DL_Assignment_2B\",\n",
        "    name=run_name,\n",
        "    config=experiment_config\n",
        ")\n",
        "\n",
        "# Begin model training\n",
        "run_training(experiment_config, data_bundle)\n"
      ],
      "metadata": {
        "id": "6K4Ma1LmkDNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define sweep configuration for hyperparameter optimization\n",
        "sweep_config = {\n",
        "    \"method\": \"bayes\",\n",
        "    \"name\": \"DL_Assignment2_Sweep\",\n",
        "    \"metric\": {\n",
        "        \"name\": \"val_accuracy\",\n",
        "        \"goal\": \"maximize\"\n",
        "    },\n",
        "    \"parameters\": {\n",
        "        \"epochs\": {\"values\": [10]},\n",
        "        \"learning_rate\": {\"values\": [0.0001, 0.001]},\n",
        "        \"batch_size\": {\"values\": [32, 64]},\n",
        "        \"num_of_filter\": {\"values\": [16, 32, 64]},\n",
        "        \"filter_size\": {\n",
        "            \"values\": [\n",
        "                [3, 3, 3, 3, 3],\n",
        "                [5, 5, 5, 5, 5],\n",
        "                [7, 7, 7, 7, 7],\n",
        "                [11, 9, 7, 5, 3],\n",
        "                [3, 5, 7, 9, 11]\n",
        "            ]\n",
        "        },\n",
        "        \"actv_func\": {\"values\": [\"elu\", \"gelu\", \"leaky_relu\", \"selu\"]},\n",
        "        \"filter_multiplier\": {\"values\": [1, 2]},\n",
        "        \"data_aug\": {\"values\": [False]},\n",
        "        \"use_batchnorm\": {\"values\": [True, False]},\n",
        "        \"dropout_rate\": {\"values\": [0, 0.1, 0.2]},\n",
        "        \"dense_units\": {\"values\": [64, 128, 256]},\n",
        "        \"conv_layer_count\": {\"values\": [5]}\n",
        "    }\n",
        "}\n",
        "\n",
        "# Initialize sweep\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project=\"DL_Assignment_2\")\n",
        "\n",
        "# Define training entry point for each sweep run\n",
        "def sweep_main():\n",
        "    wandb.init()\n",
        "    cfg = wandb.config\n",
        "\n",
        "    run_name = (\n",
        "        f\"{cfg.actv_func}_ep{cfg.epochs}_lr{cfg.learning_rate}_initF{cfg.num_of_filter}_\"\n",
        "        f\"fsz{cfg.filter_size}_fmul{cfg.filter_multiplier}_aug{cfg.data_aug}_\"\n",
        "        f\"bn{cfg.use_batchnorm}_drop{cfg.dropout_rate}_dense{cfg.dense_units}_bs{cfg.batch_size}\"\n",
        "    )\n",
        "\n",
        "    with wandb.init(project=\"DL_Assignment_2\", name=run_name, config=cfg):\n",
        "        dataset = build_data_pipeline(cfg)\n",
        "        run_training(cfg, dataset)\n",
        "\n",
        "# Launch the agent to perform sweeps\n",
        "wandb.agent(sweep_id, function=sweep_main, count=10)\n"
      ],
      "metadata": {
        "id": "7GHZlJfIkDP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 4 10 X 3\n",
        "\n",
        "import torch\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import wandb\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Configure the hyper parameters\n",
        "h_params = {\n",
        "    \"epochs\": 10,\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"batch_size\": 32,\n",
        "    \"num_of_filter\": 64,\n",
        "    \"filter_size\": [3, 3, 3, 3, 3],\n",
        "    \"actv_func\": \"gelu\",\n",
        "    \"filter_multiplier\": 2,\n",
        "    \"data_augumentation\": False,\n",
        "    \"batch_normalization\": True,\n",
        "    \"dropout\": 0.4,\n",
        "    \"conv_layers\": 5,\n",
        "    \"dense_layer_size\": 256\n",
        "}\n",
        "\n",
        "IMAGE_SIZE = 224\n",
        "NUM_OF_CLASSES = 10\n",
        "CLASS_NAMES = [\"Amphibia\", \"Animalia\", \"Arachnida\", \"Aves\", \"Fungi\",\n",
        "               \"Insecta\", \"Mammalia\", \"Mollusca\", \"Plantae\", \"Reptilia\"]\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.login(key=\"986fd96a25245251243e3084fc375526692b03b6\")\n",
        "run = wandb.init(project=\"DL_Assignment_2\", config=h_params)\n",
        "\n",
        "# Data preparation\n",
        "def split_dataset_with_class_distribution(dataset, split_ratio):\n",
        "    train_indices = []\n",
        "    val_indices = []\n",
        "    class_ranges = [(0, 999), (1000, 1999), (2000, 2999), (3000, 3999),\n",
        "                   (4000, 4998), (4999, 5998), (5999, 6998),\n",
        "                   (6999, 7998), (7999, 8998), (8999, 9998)]\n",
        "\n",
        "    for start, end in class_ranges:\n",
        "        class_indices = list(range(start, end + 1))\n",
        "        split_idx = int(len(class_indices) * split_ratio)\n",
        "        train_indices.extend(class_indices[:split_idx])\n",
        "        val_indices.extend(class_indices[split_idx:])\n",
        "\n",
        "    return Subset(dataset, train_indices), Subset(dataset, val_indices)\n",
        "\n",
        "def prepare_data(h_params):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    train_data_dir = \"/kaggle/input/dldata/inaturalist_12K/train\"\n",
        "    test_data_dir = \"/kaggle/input/dldata/inaturalist_12K/val\"\n",
        "\n",
        "    train_dataset = ImageFolder(train_data_dir, transform=transform)\n",
        "    train_dataset, val_dataset = split_dataset_with_class_distribution(train_dataset, 0.8)\n",
        "    test_dataset = ImageFolder(test_data_dir, transform=transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=h_params[\"batch_size\"], shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=h_params[\"batch_size\"], shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=h_params[\"batch_size\"], shuffle=True)\n",
        "\n",
        "    return {\n",
        "        \"train_loader\": train_loader,\n",
        "        \"val_loader\": val_loader,\n",
        "        \"test_loader\": test_loader,\n",
        "        \"train_len\": len(train_dataset),\n",
        "        \"val_len\": len(val_dataset),\n",
        "        \"test_len\": len(test_dataset)\n",
        "    }\n",
        "\n",
        "# Model definition\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, h_params):\n",
        "        super(CNN, self).__init__()\n",
        "        self.h_params = h_params\n",
        "        self.filters = [int(h_params[\"num_of_filter\"] * (h_params[\"filter_multiplier\"]**i))\n",
        "                       for i in range(h_params[\"conv_layers\"])]\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "        self.bn_layers = nn.ModuleList()\n",
        "        in_channels = 3\n",
        "\n",
        "        for i in range(h_params[\"conv_layers\"]):\n",
        "            self.conv_layers.append(\n",
        "                nn.Conv2d(in_channels, self.filters[i], h_params[\"filter_size\"][i])\n",
        "            )\n",
        "            if h_params[\"batch_normalization\"]:\n",
        "                self.bn_layers.append(nn.BatchNorm2d(self.filters[i]))\n",
        "            in_channels = self.filters[i]\n",
        "\n",
        "        # Fully connected layers\n",
        "        f_map_size = self.calculate_fmap_size(IMAGE_SIZE)\n",
        "        self.fc1 = nn.Linear(self.filters[-1] * f_map_size * f_map_size, h_params[\"dense_layer_size\"])\n",
        "        self.fc2 = nn.Linear(h_params[\"dense_layer_size\"], NUM_OF_CLASSES)\n",
        "        self.dropout = nn.Dropout(p=h_params[\"dropout\"])\n",
        "        self.activation = self.get_activation(h_params[\"actv_func\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i in range(self.h_params[\"conv_layers\"]):\n",
        "            x = self.conv_layers[i](x)\n",
        "            if self.h_params[\"batch_normalization\"]:\n",
        "                x = self.bn_layers[i](x)\n",
        "            x = self.activation(x)\n",
        "            x = F.max_pool2d(x, 2, 2)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def calculate_fmap_size(self, input_size):\n",
        "        size = input_size\n",
        "        for i in range(self.h_params[\"conv_layers\"]):\n",
        "            size = (size - self.h_params[\"filter_size\"][i] + 1) // 2\n",
        "        return size\n",
        "\n",
        "    def get_activation(self, name):\n",
        "        activations = {\n",
        "            'relu': F.relu,\n",
        "            'gelu': F.gelu,\n",
        "            'silu': F.silu,\n",
        "            'selu': F.selu,\n",
        "            'leaky_relu': F.leaky_relu,\n",
        "            'elu': F.elu\n",
        "        }\n",
        "        return activations.get(name, F.relu)\n",
        "\n",
        "# Training and evaluation\n",
        "def train_model(model, data_loaders, optimizer, criterion, device, num_epochs):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in data_loaders[\"train_loader\"]:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(data_loaders[\"train_loader\"])\n",
        "        train_acc = correct / total\n",
        "\n",
        "        # Validation\n",
        "        val_loss, val_acc = evaluate_model(model, data_loaders[\"val_loader\"], criterion, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        print(f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f}\")\n",
        "        print(f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
        "\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_acc\": train_acc,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_acc\": val_acc\n",
        "        })\n",
        "\n",
        "def evaluate_model(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return running_loss / len(loader), correct / total\n",
        "\n",
        "def create_prediction_grid(model, loader, class_names, device, n_images=30):\n",
        "    model.eval()\n",
        "    images, labels = next(iter(loader))\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images[:n_images])\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    # Create grid\n",
        "    fig, axes = plt.subplots(10, 3, figsize=(15, 30))\n",
        "    images = images[:n_images].cpu()\n",
        "\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        if i >= n_images:\n",
        "            break\n",
        "\n",
        "        img = images[i].permute(1, 2, 0).numpy()\n",
        "        img = np.clip(img, 0, 1)\n",
        "\n",
        "        true_label = class_names[labels[i]]\n",
        "        pred_label = class_names[preds[i]]\n",
        "        color = 'green' if true_label == pred_label else 'red'\n",
        "\n",
        "        ax.imshow(img)\n",
        "        ax.set_title(f\"True: {true_label}\\nPred: {pred_label}\", color=color)\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Prepare data\n",
        "    data_loaders = prepare_data(h_params)\n",
        "\n",
        "    # Initialize model\n",
        "    model = CNN(h_params).to(device)\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        model = nn.DataParallel(model)\n",
        "\n",
        "    # Training setup\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=h_params[\"learning_rate\"])\n",
        "\n",
        "    # Train model\n",
        "    train_model(model, data_loaders, optimizer, criterion, device, h_params[\"epochs\"])\n",
        "\n",
        "    # Evaluate on test set\n",
        "    test_loss, test_acc = evaluate_model(model, data_loaders[\"test_loader\"], criterion, device)\n",
        "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "    wandb.log({\"test_acc\": test_acc})\n",
        "\n",
        "    # Create and save prediction grid\n",
        "    pred_grid = create_prediction_grid(model, data_loaders[\"test_loader\"], CLASS_NAMES, device)\n",
        "    plt.savefig(\"prediction_grid.png\")\n",
        "    wandb.log({\"prediction_grid\": wandb.Image(pred_grid)})\n",
        "\n",
        "    # Save model\n",
        "    torch.save(model.state_dict(), \"best_model.pth\")\n",
        "    wandb.save(\"best_model.pth\")\n",
        "\n",
        "    wandb.finish()"
      ],
      "metadata": {
        "id": "rLu7ShPWkDTa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dVJwUgxA4rJN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}